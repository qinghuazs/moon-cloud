# App Store 爬虫功能实现文档

## 概述

本文档描述了 App Store 分类页面爬虫功能的实现，用于抓取各分类下的应用链接并存储到 Redis 队列中。

## 实现内容

### 1. 添加的依赖

在 `pom.xml` 中添加了 Jsoup 依赖用于 HTML 解析：

```xml
<!-- Jsoup for HTML parsing -->
<dependency>
    <groupId>org.jsoup</groupId>
    <artifactId>jsoup</artifactId>
    <version>1.17.2</version>
</dependency>
```

### 2. 爬虫服务接口

**文件**: `src/main/java/com/moon/cloud/appstore/service/CrawlerService.java`

主要方法：
- `crawlAppsByCategoryId(String categoryId)` - 根据分类ID爬取应用
- `crawlAllCategories()` - 爬取所有分类
- `fetchPageContent(String url)` - 获取页面内容
- `extractAppLinks(String htmlContent)` - 提取应用链接
- `pushLinksToRedisQueue(List<String> appLinks, String queueName)` - 推送到Redis队列

### 3. 爬虫服务实现

**文件**: `src/main/java/com/moon/cloud/appstore/service/impl/CrawlerServiceImpl.java`

核心功能：
- 使用 Jsoup 抓取 App Store 分类页面
- 通过 CSS 选择器 `.we-lockup.targeted-link[href]` 提取应用链接
- 将提取的链接存储到 Redis 队列（格式：`appstore:queue:{categoryId}`）
- 队列设置 7 天过期时间

### 4. 爬虫控制器

**文件**: `src/main/java/com/moon/cloud/appstore/controller/CrawlerController.java`

提供的 REST API：
- `POST /api/appstore/crawler/crawl/category/{categoryId}` - 爬取指定分类
- `POST /api/appstore/crawler/crawl/all` - 爬取所有分类
- `GET /api/appstore/crawler/queue/{queueName}/size` - 获取队列大小
- `DELETE /api/appstore/crawler/queue/{queueName}` - 清空队列
- `POST /api/appstore/crawler/test/extract` - 测试链接提取
- `GET /api/appstore/crawler/test/fetch` - 测试页面抓取

### 5. 简化版爬虫控制器

**文件**: `src/main/java/com/moon/cloud/appstore/controller/SimpleCrawlerController.java`

由于项目存在一些实体依赖问题，创建了一个简化版的爬虫控制器：
- `POST /api/appstore/simple-crawler/crawl/{categoryId}` - 直接爬取并返回结果
- `GET /api/appstore/simple-crawler/test` - 测试爬虫服务

## 使用示例

### 1. 爬取指定分类

```bash
curl -X POST http://localhost:8082/api/appstore/simple-crawler/crawl/6004
```

响应示例：
```json
{
  "success": true,
  "categoryId": "6004",
  "crawledCount": 50,
  "links": [
    "https://apps.apple.com/cn/app/id123456",
    "https://apps.apple.com/cn/app/id789012"
  ],
  "message": "成功爬取 50 个应用链接"
}
```

### 2. 测试爬虫服务

```bash
curl http://localhost:8082/api/appstore/simple-crawler/test
```

响应示例：
```json
{
  "status": "ok",
  "message": "爬虫服务运行正常",
  "redisAvailable": true
}
```

## Redis 队列结构

爬取的应用链接存储在 Redis 列表中：

- **队列名称格式**: `appstore:queue:{categoryId}`
- **数据格式**: 完整的应用链接 URL
- **过期时间**: 7 天

示例：
```
appstore:queue:6004 -> [
  "https://apps.apple.com/cn/app/id123456",
  "https://apps.apple.com/cn/app/id789012",
  ...
]
```

## 技术要点

1. **HTML 解析**: 使用 Jsoup 库进行 HTML 解析，支持 CSS 选择器
2. **网络请求**: 设置合理的 User-Agent 和超时时间（30秒）
3. **错误处理**: 捕获网络异常和解析异常，返回友好的错误信息
4. **Redis 操作**: 使用 Spring Data Redis 的 ListOperations 进行队列操作
5. **速率限制**: 批量爬取时添加 2 秒延时，避免请求过快

## 更新记录

### 2024-09-26 更新
- ✅ 已修改 `CrawlerServiceImpl.crawlAppsByCategoryId` 方法，从数据库获取分类信息
- ✅ 已修改 `CrawlerServiceImpl.crawlAllCategories` 方法，从数据库获取所有激活的分类
- ✅ 添加了 `CategoryMapper` 依赖注入
- ✅ 使用 MyBatis Plus 的 `LambdaQueryWrapper` 查询激活且有 URL 的分类
- ✅ **重要修正**：使用 `category_id` 字段查询而非主键 `id`
  - `crawlAppsByCategoryId` 现在使用 `.eq(Category::getCategoryId, categoryId)` 查询
  - `crawlAllCategories` 遍历时使用 `category.getCategoryId()` 而非 `getId()`

## 注意事项

1. **分类URL配置**: ✅ 已实现从数据库的 `categories` 表 `categories_url` 字段读取
2. **CSS选择器**: App Store 页面结构可能变化，需要定期检查选择器是否有效
3. **爬取频率**: 建议控制爬取频率，避免被反爬虫机制限制
4. **数据处理**: 爬取的链接后续需要进一步处理，获取应用详细信息

## API 文档更新

已在 `API-DOCUMENTATION.md` 中添加了爬虫管理接口的完整文档，包括：
- 接口地址
- 请求参数
- 响应示例
- 使用说明

## 后续优化建议

1. **完善实体类**: 补充缺失的实体字段，使爬虫服务能够正确从数据库读取分类信息
2. **异步处理**: 使用异步任务处理大批量爬取，提高性能
3. **重试机制**: 添加失败重试机制，提高爬取成功率
4. **监控告警**: 添加爬取失败的监控和告警机制
5. **数据验证**: 验证爬取的链接有效性，过滤无效数据